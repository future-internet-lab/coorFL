{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import src.Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = string.ascii_lowercase + string.digits + \".\"\n",
    "char2idx = {c: i + 1 for i, c in enumerate(ALPHABET)}  # padding=0\n",
    "idx2char = {i: c for c, i in char2idx.items()}       # Reverse mapping index -> character\n",
    "vocab_size = len(char2idx) + 1\n",
    "\n",
    "MAX_LEN = 50\n",
    "def domain_to_tensor(domain):\n",
    "    arr = [char2idx.get(c, 0) for c in domain.lower()][:MAX_LEN]\n",
    "    arr += [0] * (MAX_LEN - len(arr))\n",
    "    return torch.tensor(arr, dtype=torch.long)\n",
    "\n",
    "def tensor_to_domain(tensor):\n",
    "    \"\"\"\n",
    "    Converts a tensor back into a domain string.\n",
    "    - Ignores padding (index=0).\n",
    "    - Uses idx2char to map indices back to characters.\n",
    "\n",
    "    Args:\n",
    "    - tensor: A 1D PyTorch tensor representing the encoded domain.\n",
    "\n",
    "    Returns:\n",
    "    - str: Decoded domain name.\n",
    "    \"\"\"\n",
    "    domain = \"\".join(idx2char.get(idx, \"\") for idx in tensor.tolist() if idx > 0)  # Ignore padding (0)\n",
    "    return domain\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        dataloader = pickle.load(file)\n",
    "    print(f\"DataLoader loaded from {file_path}.\")\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class DomainDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dom, lbl = self.samples[idx]\n",
    "        x = domain_to_tensor(dom)\n",
    "        return x, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loaded from domain2/benign_train.pkl.\n",
      "DataLoader loaded from domain2/dga_1_train.pkl.\n",
      "DataLoader loaded from domain2/dga_2_train.pkl.\n",
      "DataLoader loaded from domain2/dga_3_train.pkl.\n",
      "DataLoader loaded from domain2/dga_4_train.pkl.\n"
     ]
    }
   ],
   "source": [
    "benign_train_ds = load_dataset(\"domain2/benign_train.pkl\")\n",
    "dga_1_train_ds = load_dataset(\"domain2/dga_1_train.pkl\")\n",
    "dga_2_train_ds = load_dataset(\"domain2/dga_2_train.pkl\")\n",
    "dga_3_train_ds = load_dataset(\"domain2/dga_3_train.pkl\")\n",
    "dga_4_train_ds = load_dataset(\"domain2/dga_4_train.pkl\")\n",
    "\n",
    "    # Tạo các tập con kết hợp\n",
    "all_train_datasets = [\n",
    "    ConcatDataset([benign_train_ds, dga_1_train_ds]),\n",
    "    ConcatDataset([benign_train_ds, dga_2_train_ds]),\n",
    "    ConcatDataset([benign_train_ds, dga_3_train_ds]),\n",
    "    ConcatDataset([benign_train_ds, dga_4_train_ds])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=50):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "\n",
    "# Transformer Model for DGA Detection\n",
    "class PositionalEncodingTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_size, embed_dim=64, nhead=4, num_layers=4, dim_feedforward=256, dropout=0.2,\n",
    "                 num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "\n",
    "        # Transformer Encoder Layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=\"relu\",\n",
    "            layer_norm_eps=1e-5,\n",
    "            batch_first=True  # Fix the warning by enabling batch_first\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Fully Connected Output Layer\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        # Dropout & Layer Normalization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding Layer\n",
    "        emb = self.embedding(x)  # (B, L, E)\n",
    "        emb = self.positional_encoding(emb)  # Add positional encodings\n",
    "        emb = self.dropout(emb)  # Apply dropout\n",
    "        emb = self.layer_norm(emb)  # Apply Layer Normalization\n",
    "\n",
    "        # Transformer Encoder (no permute needed now)\n",
    "        out = self.transformer_encoder(emb)  # (B, L, E)\n",
    "\n",
    "        # Extract final representation (use first token's output)\n",
    "        out_final = out[:, 0, :]  # (Batch, Embed_Dim)\n",
    "\n",
    "        # Fully Connected Output\n",
    "        logits = self.fc(out_final)  # (Batch, Num_Classes)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = all_train_datasets[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Sử dụng BCELoss cho phân loại nhị phân\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_device(model, lr, momentum, trainloader, data_name, criterion, epoch = 1, clip_grad_norm=None):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(epoch):\n",
    "        for (training_data, label) in tqdm(trainloader):\n",
    "            if training_data.size(0) == 1:\n",
    "                continue\n",
    "            training_data = training_data.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if data_name == \"DOMAIN2\":\n",
    "                output = model(training_data)\n",
    "                output = torch.softmax(output, dim=1)[:, 1]\n",
    "                loss = criterion(output, label.float())\n",
    "            else:\n",
    "                output = model(training_data)\n",
    "                loss = criterion(output, label)\n",
    "\n",
    "            if torch.isnan(loss).any():\n",
    "                src.Log.print_with_color(\"NaN detected in loss, stop training\", \"yellow\")\n",
    "                return False\n",
    "\n",
    "            loss.backward()\n",
    "            if clip_grad_norm and clip_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả phân cụm: {3: [0, 4, 6], 1: [1, 2, 3, 8], 2: [5, 7], 4: [9]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "def Clustering_Hierarchical(interference_output, config):\n",
    "    \"\"\"\n",
    "    Tính toán ma trận tương đồng và thực hiện phân cụm phân cấp (Hierarchical Clustering).\n",
    "    \n",
    "    :param interference_output: Mảng numpy chứa các vector đặc trưng đầu ra của các client.\n",
    "    :param config: Dictionary chứa các tham số cấu hình, bao gồm 'threshold' để kiểm soát ngưỡng phân cụm.\n",
    "    :return: Dictionary chứa các cụm, mỗi cụm là một danh sách các client_id.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lấy ngưỡng từ cấu hình\n",
    "    threshold = config['threshold']\n",
    "    \n",
    "    # Tính toán ma trận tương đồng Cosine giữa các client\n",
    "    similarity_matrix = cosine_similarity(interference_output)\n",
    "    \n",
    "    # Chuyển ma trận tương đồng thành khoảng cách (distance matrix)\n",
    "    distance_matrix = 1 - similarity_matrix  # Cosine distance = 1 - Cosine similarity\n",
    "    \n",
    "    # Áp dụng thuật toán liên kết phân cấp (Hierarchical Clustering) để tính toán mối quan hệ giữa các điểm\n",
    "    # Dùng phương pháp 'ward' (hoặc có thể thử các phương pháp khác như 'single', 'complete', 'average')\n",
    "    Z = linkage(distance_matrix, method='ward')\n",
    "    \n",
    "    # Dự đoán nhóm của các client dựa trên ngưỡng (threshold)\n",
    "    # fcluster dùng để tạo các nhóm (clusters) từ kết quả của linkage, ngưỡng 'threshold' xác định khi nào các nhóm được hợp nhất.\n",
    "    # Nếu ngưỡng 'threshold' thấp, các nhóm sẽ được phân tách rõ ràng hơn.\n",
    "    clusters = fcluster(Z, threshold, criterion='distance')\n",
    "    \n",
    "    # Tạo danh sách các nhóm (clusters) từ các client\n",
    "    final_clusters = {}\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        if cluster_id not in final_clusters:\n",
    "            final_clusters[cluster_id] = []\n",
    "        final_clusters[cluster_id].append(idx)  # Lưu client id vào cluster tương ứng\n",
    "\n",
    "    return final_clusters\n",
    "\n",
    "# Ví dụ cấu hình và dữ liệu ngẫu nhiên\n",
    "config = {\n",
    "    'threshold': 0.5  # Ngưỡng phân cụm\n",
    "}\n",
    "\n",
    "# Giả lập dữ liệu interference_output với 10 client, mỗi client có 5 giá trị đầu ra\n",
    "interference_output = np.random.rand(10, 5)\n",
    "\n",
    "# Gọi hàm Clustering_Hierarchical\n",
    "clusters = Clustering_Hierarchical(interference_output, config)\n",
    "\n",
    "# In kết quả phân cụm\n",
    "print(\"Kết quả phân cụm:\", clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def calculating_adjacency(interference_output): \n",
    "    \"\"\"\n",
    "    Tính toán ma trận tương đồng giữa các client sử dụng phép nhân vô hướng và arccos.\n",
    "    \n",
    "    :param interference_output: Mảng numpy chứa các vector đặc trưng đầu ra của các client.\n",
    "    :return: Ma trận tương đồng giữa các client.\n",
    "    \"\"\"\n",
    "    nclients = interference_output.shape[0]  # Lấy số lượng client (hàng của ma trận interference_output)\n",
    "    sim_mat = np.zeros([nclients, nclients])  # Khởi tạo ma trận tương đồng\n",
    "    \n",
    "    for idx1 in range(nclients):\n",
    "        for idx2 in range(nclients):\n",
    "            # Lấy các vector đặc trưng của client idx1 và idx2 từ interference_output\n",
    "            U1 = copy.deepcopy(interference_output[idx1])\n",
    "            U2 = copy.deepcopy(interference_output[idx2])\n",
    "            \n",
    "            # Tính phép nhân vô hướng giữa hai vector U1 và U2\n",
    "            mul = np.clip(U1.T @ U2, a_min=-1.0, a_max=1.0)  # Đảm bảo giá trị nằm trong khoảng [-1, 1]\n",
    "            \n",
    "            # Tính giá trị arccos của phép nhân vô hướng\n",
    "            sim_mat[idx1, idx2] = 100 * np.min(np.arccos(mul))  # Chuyển đổi thành cosine similarity rồi nhân 100\n",
    "            \n",
    "    return sim_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma trận tương đồng:\n",
      " [[ 82.57485822 124.02658646  93.58231826  77.79567072  38.99318269]\n",
      " [124.02658646 133.3529019  117.46145036 108.32099878  93.75557069]\n",
      " [ 93.58231826 117.46145036   0.           0.           0.        ]\n",
      " [ 77.79567072 108.32099878   0.           0.           0.        ]\n",
      " [ 38.99318269  93.75557069   0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Giả sử có 5 client, mỗi client có vector đặc trưng 4 chiều\n",
    "interference_output = np.random.rand(5, 4)  # Dữ liệu ngẫu nhiên cho các client\n",
    "\n",
    "# Tính ma trận tương đồng\n",
    "sim_matrix = calculating_adjacency(interference_output)\n",
    "\n",
    "# In ma trận tương đồng\n",
    "print(\"Ma trận tương đồng:\\n\", sim_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.37454012, 0.95071431, 0.73199394, 0.59865848],\n",
       "        [0.15601864, 0.15599452, 0.05808361, 0.86617615],\n",
       "        [0.60111501, 0.70807258, 0.02058449, 0.96990985],\n",
       "        [0.83244264, 0.21233911, 0.18182497, 0.18340451],\n",
       "        [0.30424224, 0.52475643, 0.43194502, 0.29122914]]),\n",
       " [0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Giả sử có 5 client, mỗi client có vector đặc trưng 4 chiều\n",
    "np.random.seed(42)  # Đặt seed để dữ liệu ngẫu nhiên có thể tái tạo\n",
    "\n",
    "n_clients = 5\n",
    "output_length = 4\n",
    "\n",
    "# Tạo dữ liệu ngẫu nhiên cho U (mỗi client có một vector đặc trưng 4 chiều)\n",
    "U = np.random.rand(n_clients, output_length)\n",
    "\n",
    "# Tạo clients_idxs để chỉ định các chỉ số client\n",
    "clients_idxs = list(range(n_clients))\n",
    "\n",
    "# Kiểm tra dữ liệu ngẫu nhiên\n",
    "U, clients_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          69.53929344   0.          71.27775742   0.        ]\n",
      " [ 69.53929344  63.96396117   0.         123.19259001 115.19888867]\n",
      " [  0.           0.           0.          58.74189861  56.27191591]\n",
      " [ 71.27775742 123.19259001  58.74189861  63.55485614 105.10711102]\n",
      " [  0.         115.19888867  56.27191591 105.10711102  87.71780822]]\n"
     ]
    }
   ],
   "source": [
    "def calculating_adjacency(clients_idxs, U): \n",
    "        \n",
    "    nclients = len(clients_idxs)\n",
    "    \n",
    "    sim_mat = np.zeros([nclients, nclients])\n",
    "    for idx1 in range(nclients):\n",
    "        for idx2 in range(nclients):\n",
    "            #print(idx1)\n",
    "            #print(U)\n",
    "            #print(idx1)\n",
    "            U1 = copy.deepcopy(U[clients_idxs[idx1]])\n",
    "            U2 = copy.deepcopy(U[clients_idxs[idx2]])\n",
    "            \n",
    "            #sim_mat[idx1,idx2] = np.where(np.abs(U1.T@U2) > 1e-2)[0].shape[0]\n",
    "            #sim_mat[idx1,idx2] = 10*np.linalg.norm(U1.T@U2 - np.eye(15), ord='fro')\n",
    "            #sim_mat[idx1,idx2] = 100/np.pi*(np.sort(np.arccos(U1.T@U2).reshape(-1))[0:4]).sum()\n",
    "            mul = np.clip(U1.T@U2 ,a_min =-1.0, a_max=1.0)\n",
    "            sim_mat[idx1,idx2] = 100*np.min(np.arccos(mul))\n",
    "           \n",
    "    return sim_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  2.04195524e-01  3.05896091e-01  1.16146762e-01\n",
      "   4.32613831e-02]\n",
      " [ 2.04195524e-01  1.11022302e-16  6.34609524e-01  1.37004235e-01\n",
      "   1.56800555e-01]\n",
      " [ 3.05896091e-01  6.34609524e-01  1.11022302e-16  3.15166866e-01\n",
      "   4.47062583e-01]\n",
      " [ 1.16146762e-01  1.37004235e-01  3.15166866e-01 -2.22044605e-16\n",
      "   2.15799280e-01]\n",
      " [ 4.32613831e-02  1.56800555e-01  4.47062583e-01  2.15799280e-01\n",
      "   2.22044605e-16]]\n",
      "Số lượng cụm: 2\n",
      "Nhóm các client: [1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "def Clustering_Hierarchical(interference_output, config):\n",
    "    \"\"\"\n",
    "    Tính toán ma trận tương đồng và thực hiện phân cụm phân cấp (Hierarchical Clustering).\n",
    "    \n",
    "    :param interference_output: Mảng numpy chứa các vector đặc trưng đầu ra của các client.\n",
    "    :param config: Dictionary chứa các tham số cấu hình, bao gồm 'threshold' để kiểm soát ngưỡng phân cụm.\n",
    "    :return: Số lượng cụm, nhãn các nhóm (labels), None\n",
    "    \"\"\"\n",
    "    threshold = config['threshold']  # Lấy ngưỡng từ cấu hình\n",
    "    \n",
    "    # Tính toán ma trận tương đồng Cosine giữa các client\n",
    "    similarity_matrix = cosine_similarity(interference_output)\n",
    "    \n",
    "    # Chuyển ma trận tương đồng thành khoảng cách (distance matrix)\n",
    "    distance_matrix = 1 - similarity_matrix  # Cosine distance = 1 - Cosine similarity\n",
    "    print(distance_matrix)\n",
    "    \n",
    "    # Áp dụng thuật toán phân cụm phân cấp (Hierarchical Clustering)\n",
    "    Z = linkage(distance_matrix, method='ward')\n",
    "    \n",
    "    # Dự đoán nhóm của các client dựa trên ngưỡng (threshold)\n",
    "    labels = fcluster(Z, threshold, criterion='distance')\n",
    "    \n",
    "    # Số lượng cụm (clusters)\n",
    "    num_clusters = len(np.unique(labels))  # Đếm số lượng nhóm (cụm)\n",
    "    \n",
    "    return num_clusters, labels, None\n",
    "\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "\n",
    "# Giả sử có 5 client với 4 chiều đặc trưng\n",
    "interference_output = np.random.rand(5, 4)  # Dữ liệu ngẫu nhiên cho 5 client\n",
    "\n",
    "# Cấu hình với ngưỡng phân cụm\n",
    "config = {\n",
    "    'threshold': 0.5 # Ngưỡng phân cụm\n",
    "}\n",
    "\n",
    "# Gọi hàm Clustering_Hierarchical\n",
    "num_clusters, labels, _ = Clustering_Hierarchical(interference_output, config)\n",
    "\n",
    "# In kết quả phân cụm\n",
    "print(\"Số lượng cụm:\", num_clusters)\n",
    "print(\"Nhóm các client:\", labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
